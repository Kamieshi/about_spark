{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = ' --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.1 pyspark-shell'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "session = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master(\"local[2]\")\n",
    "    .appName(\"Driver\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "session.sparkContext.setLogLevel('WARN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "session.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "source = (session.readStream\n",
    "          .format(\"kafka\")\n",
    "          .option('kafka.bootstrap.servers', 'localhost:9092')\n",
    "          .option('subscribe', 'stream_topic')\n",
    "          ).load()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = (source\n",
    "      .selectExpr('CAST(value AS STRING)', 'offset'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "console = (df\n",
    "           .writeStream\n",
    "           .format('console')\n",
    "           .outputMode(\"append\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "console.start().awaitTermination()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "writer_to_csv = (\n",
    "    df\n",
    "    .writeStream\n",
    "    .format(\"csv\")\n",
    "    .option(\"path\", \"./data\")\n",
    "    .outputMode(\"append\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/08 11:44:42 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "Cannot start query with name kafka-output_ as a query with that name is already active in this SparkSession",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIllegalArgumentException\u001B[0m                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m write_to_kafka \u001B[38;5;241m=\u001B[39m (df\n\u001B[1;32m      2\u001B[0m                   \u001B[38;5;241m.\u001B[39mwriteStream\n\u001B[1;32m      3\u001B[0m                   \u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkafka\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      6\u001B[0m                   \u001B[38;5;241m.\u001B[39moption(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtopic\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput00\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m                   \u001B[38;5;241m.\u001B[39moption(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcheckpointLocation\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./.local/checkpoint\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m----> 8\u001B[0m \u001B[43mwrite_to_kafka\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mawaitTermination()\n",
      "File \u001B[0;32m~/PycharmProjects/SparkArticle/venv/lib/python3.8/site-packages/pyspark/sql/streaming.py:1389\u001B[0m, in \u001B[0;36mDataStreamWriter.start\u001B[0;34m(self, path, format, outputMode, partitionBy, queryName, **options)\u001B[0m\n\u001B[1;32m   1387\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mqueryName(queryName)\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sq(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jwrite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1391\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sq(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jwrite\u001B[38;5;241m.\u001B[39mstart(path))\n",
      "File \u001B[0;32m~/PycharmProjects/SparkArticle/venv/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
      "File \u001B[0;32m~/PycharmProjects/SparkArticle/venv/lib/python3.8/site-packages/pyspark/sql/utils.py:196\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    192\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    194\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mIllegalArgumentException\u001B[0m: Cannot start query with name kafka-output_ as a query with that name is already active in this SparkSession"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1187\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "write_to_kafka = (df\n",
    "                  .writeStream\n",
    "                  .format('kafka')\n",
    "                  .queryName('kafka-output_')\n",
    "                  .option('kafka.bootstrap.servers', 'localhost:9092')\n",
    "                  .option('topic', 'output00')\n",
    "                  .option('checkpointLocation', './.local/checkpoint'))\n",
    "write_to_kafka.start().awaitTermination()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1043\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1125|  7109|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1044\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1126|  7110|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1045\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1127|  7111|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1046\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1128|  7112|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1047\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1129|  7113|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1048\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1130|  7114|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1049\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1131|  7115|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1050\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1132|  7116|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1051\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1133|  7117|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1052\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1134|  7118|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1053\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1135|  7119|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1054\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1136|  7120|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1055\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1137|  7121|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1056\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1138|  7122|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1057\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1139|  7123|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1058\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1140|  7124|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1059\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1141|  7125|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1060\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1142|  7126|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1061\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1143|  7127|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1062\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1144|  7128|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1063\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1145|  7129|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1064\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1146|  7130|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1065\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1147|  7131|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1066\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1148|  7132|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1067\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1149|  7133|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1068\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1150|  7134|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1069\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1151|  7135|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1070\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1152|  7136|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1071\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1153|  7137|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1072\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1154|  7138|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1073\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1155|  7139|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1074\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1156|  7140|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1075\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1157|  7141|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1076\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1158|  7142|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1077\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1159|  7143|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1078\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1160|  7144|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1079\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1161|  7145|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1080\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1162|  7146|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1081\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1163|  7147|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1082\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1164|  7148|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1083\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1165|  7149|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1084\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1166|  7150|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1085\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1167|  7151|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1086\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1168|  7152|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1087\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1169|  7153|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1088\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1170|  7154|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1089\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1171|  7155|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1090\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1172|  7156|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1091\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1173|  7157|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1092\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1174|  7158|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1093\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1175|  7159|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1094\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1176|  7160|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1095\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1177|  7161|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1096\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1178|  7162|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1097\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1179|  7163|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1098\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1180|  7164|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1099\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1181|  7165|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1100\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1182|  7166|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1101\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1183|  7167|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1102\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1184|  7168|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1103\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1185|  7169|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1104\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1186|  7170|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1105\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1187|  7171|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1106\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1188|  7172|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1107\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1189|  7173|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1108\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1190|  7174|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1109\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1191|  7175|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1110\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1192|  7176|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1111\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1193|  7177|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1112\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1194|  7178|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1113\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1195|  7179|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1114\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1196|  7180|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1115\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1197|  7181|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1116\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1198|  7182|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1117\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1199|  7183|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1118\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1200|  7184|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1119\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1201|  7185|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1120\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1202|  7186|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1121\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1203|  7187|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1122\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1204|  7188|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1123\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1205|  7189|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1124\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1206|  7190|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1125\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1207|  7191|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1126\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1208|  7192|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1127\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1209|  7193|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1128\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1210|  7194|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1129\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1211|  7195|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1130\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1212|  7196|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1131\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1213|  7197|\n",
      "+----------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Batch: 1132\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1214|  7198|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1133\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1215|  7199|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1134\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1216|  7200|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1135\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1217|  7201|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1136\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1218|  7202|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1137\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1219|  7203|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1138\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1220|  7204|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1139\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1221|  7205|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1140\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1222|  7206|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1141\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1223|  7207|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1142\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1224|  7208|\n",
      "+----------------+------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1143\n",
      "-------------------------------------------\n",
      "+----------------+------+\n",
      "|           value|offset|\n",
      "+----------------+------+\n",
      "|Data number 1225|  7209|\n",
      "+----------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dmitryrusack/PycharmProjects/SparkArticle/venv/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/dmitryrusack/PycharmProjects/SparkArticle/venv/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m session\u001B[38;5;241m.\u001B[39mconf\u001B[38;5;241m.\u001B[39mset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspark.sql.streaming.checkpointLocation\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./checkPoint\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mwriter_to_csv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mawaitTermination\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/SparkArticle/venv/lib/python3.8/site-packages/pyspark/sql/streaming.py:107\u001B[0m, in \u001B[0;36mStreamingQuery.awaitTermination\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jsq\u001B[38;5;241m.\u001B[39mawaitTermination(\u001B[38;5;28mint\u001B[39m(timeout \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m))\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jsq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mawaitTermination\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/SparkArticle/venv/lib/python3.8/site-packages/py4j/java_gateway.py:1320\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1313\u001B[0m args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_args(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[0;32m-> 1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1322\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
      "File \u001B[0;32m~/PycharmProjects/SparkArticle/venv/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001B[0m, in \u001B[0;36mGatewayClient.send_command\u001B[0;34m(self, command, retry, binary)\u001B[0m\n\u001B[1;32m   1036\u001B[0m connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_connection()\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1038\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1039\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m binary:\n\u001B[1;32m   1040\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_connection_guard(connection)\n",
      "File \u001B[0;32m~/PycharmProjects/SparkArticle/venv/lib/python3.8/site-packages/py4j/clientserver.py:511\u001B[0m, in \u001B[0;36mClientServerConnection.send_command\u001B[0;34m(self, command)\u001B[0m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 511\u001B[0m         answer \u001B[38;5;241m=\u001B[39m smart_decode(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m    512\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAnswer received: \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(answer))\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001B[39;00m\n\u001B[1;32m    514\u001B[0m         \u001B[38;5;66;03m# answer before the socket raises an error.\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.8/socket.py:669\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    667\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    668\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 669\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    670\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    671\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "session.conf.set(\"spark.sql.streaming.checkpointLocation\", \"./checkPoint\")\n",
    "writer_to_csv.start().awaitTermination()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accum = session.sparkContext.accumulator(0)\n",
    "foreach_data = (\n",
    "    df\n",
    "    .writeStream\n",
    "    .foreach(lambda x: accum.add(1))\n",
    "    .start()\n",
    "    .awaitTermination()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accum.value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/08 11:45:15 ERROR WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@e5b1dda is aborting.\n",
      "22/09/08 11:45:15 ERROR WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@e5b1dda aborted.\n",
      "22/09/08 11:45:15 ERROR WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@118f92f7 is aborting.\n",
      "22/09/08 11:45:15 ERROR WriteToDataSourceV2Exec: Data source write support org.apache.spark.sql.execution.streaming.sources.MicroBatchWrite@118f92f7 aborted.\n",
      "22/09/08 11:45:15 ERROR FileFormatWriter: Aborting job ba159fd9-71d0-402b-acb7-63bd7c636171.\n",
      "java.lang.IllegalStateException: SparkContext has been shutdown\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2220)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:245)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink.addBatch(FileStreamSink.scala:181)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:660)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:658)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:658)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:255)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:212)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:285)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:208)\n",
      "22/09/08 11:45:15 ERROR MicroBatchExecution: Query [id = 09dddfcb-ab4a-4917-a6d7-8edf08ec7113, runId = d71d760d-3d19-41c7-a69a-9460c37a4b72] terminated with error\n",
      "org.apache.spark.SparkException: Job aborted.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:638)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:278)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink.addBatch(FileStreamSink.scala:181)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:660)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:658)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:658)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:255)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:212)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:285)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:208)\n",
      "Caused by: java.lang.IllegalStateException: SparkContext has been shutdown\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2220)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:245)\n",
      "\t... 25 more\n",
      "22/09/08 11:45:15 ERROR MicroBatchExecution: Query kafka-output_ [id = a7eb7def-6670-4516-ad07-ff210295919d, runId = 1acf3757-eabb-4e8d-8339-bbb942a50785] terminated with error\n",
      "org.apache.spark.SparkException: Writing job aborted\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.writingJobAbortedError(QueryExecutionErrors.scala:749)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:409)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:353)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:302)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:313)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3120)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3120)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:663)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:658)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:658)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:255)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:212)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:285)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:208)\n",
      "Caused by: org.apache.spark.SparkException: Job 1601 cancelled because SparkContext was shut down\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1188)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1186)\n",
      "\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1186)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2887)\n",
      "\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2784)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$11(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.stop(JavaSparkContext.scala:550)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:377)\n",
      "\t... 42 more\n",
      "22/09/08 11:45:15 ERROR MicroBatchExecution: Query [id = d8d7913c-97d1-4c5b-952a-f40a817e2702, runId = ff37048e-fddd-4b7b-8613-0555a314a670] terminated with error\n",
      "org.apache.spark.SparkException: Writing job aborted\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.writingJobAbortedError(QueryExecutionErrors.scala:749)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:409)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:353)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.writeWithV2(WriteToDataSourceV2Exec.scala:302)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec.run(WriteToDataSourceV2Exec.scala:313)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n",
      "\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:3120)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n",
      "\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:3120)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:663)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:658)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:658)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:255)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:68)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:218)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:212)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:307)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:285)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:208)\n",
      "Caused by: org.apache.spark.SparkException: Job 1602 cancelled because SparkContext was shut down\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1(DAGScheduler.scala:1188)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$cleanUpAfterSchedulerStop$1$adapted(DAGScheduler.scala:1186)\n",
      "\tat scala.collection.mutable.HashSet.foreach(HashSet.scala:79)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:1186)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:2887)\n",
      "\tat org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:2784)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$stop$11(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1484)\n",
      "\tat org.apache.spark.SparkContext.stop(SparkContext.scala:2095)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.stop(JavaSparkContext.scala:550)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:377)\n",
      "\t... 42 more\n"
     ]
    }
   ],
   "source": [
    "session.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}